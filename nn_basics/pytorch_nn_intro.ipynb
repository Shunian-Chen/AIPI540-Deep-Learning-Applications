{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wplhw_Z72YE"
      },
      "source": [
        "<a href='https://ai.meng.duke.edu'> = <img align=\"left\" style=\"padding-top:10px;\" src=https://storage.googleapis.com/aipi_datasets/Duke-AIPI-Logo.png>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZA3j7RY72YK"
      },
      "source": [
        "# Deep Learning in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWDJAQE472YL",
        "outputId": "a682d109-f600-4174-840c-d00e591f5985"
      },
      "outputs": [],
      "source": [
        "# Run this cell only if working in Colab\n",
        "# Connects to any needed files from GitHub and Google Drive\n",
        "import os\n",
        "\n",
        "# Remove Colab default sample_data\n",
        "!rm -r ./sample_data\n",
        "\n",
        "# Clone GitHub files to colab workspace\n",
        "git_user = \"AIPI540\" # Enter user or organization name\n",
        "git_email = \"jon.reifschneider@gmail.com\" # Enter your email\n",
        "repo_name = \"class_demos\" # Enter repo name\n",
        "# Use the below if repo is private, or is public and you want to push to it\n",
        "# Otherwise comment next two lines out\n",
        "#git_token = input(\"enter git token\") # Enter your github token \n",
        "#git_path = f\"https://{git_token}@github.com/{git_user}/{repo_name}.git\"\n",
        "# Use the below instead if repo is public and you do not need to push to it\n",
        "git_path = 'https://github.com/AIPI540/class_demos.git' #Enter repo url\n",
        "!git clone \"{git_path}\"\n",
        "\n",
        "# Install dependencies from requirements.txt file\n",
        "#!pip install -r \"{os.path.join(repo_name,'requirements.txt')}\"\n",
        "\n",
        "# Change working directory to location of notebook\n",
        "notebook_dir = 'nn_basics'\n",
        "path_to_notebook = os.path.join(repo_name,notebook_dir)\n",
        "%cd \"{path_to_notebook}\"\n",
        "%ls\n",
        "\n",
        "# Mount Google drive to access files there\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# # Path to files in Google Drive\n",
        "# path_to_gdrive_files = '../../gdrive/MyDrive/AIPI540/class_demos/computer_vision'\n",
        "# # Display contents\n",
        "# print('Contents of gdrive directory:')\n",
        "# print(os.listdir(path_to_gdrive_files))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIvEaDt-72YP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkRvVd3Z72YP"
      },
      "source": [
        "# Binary classification\n",
        "For binary classification, we can use a sigmoid activation function on the output layer to get our predictions in the range (0,1) and then use PyTorch's `BCELoss()` loss function (equivalent to Negative Log Likelihood)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MO46TQAQ72YQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "data=load_breast_cancer(as_frame=True)\n",
        "X,y=data.data,data.target\n",
        "# Since the default in the file is 0=malignant 1=benign we want to reverse these\n",
        "y=(y==0).astype(int)\n",
        "X,y= np.array(X),np.array(y)\n",
        "\n",
        "# Let's set aside a test set and use the remainder for training and cross-validation\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y, random_state=0,test_size=0.2)\n",
        "\n",
        "# Let's scale our data to help the algorithm converge faster\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHkRRB2e72YQ"
      },
      "source": [
        "### Step 1: Set up dataloaders for our data\n",
        "The first step is to set up the dataloaders to feed our data into the model.  We first create a `TensorDataset` for our training data and our test data.  Then we create `DataLoaders` for the training and test data which allow us to iteratively feed the data into our model in batches (called \"mini-batches\") of a size that we can specify."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdmkOLqh72YR"
      },
      "outputs": [],
      "source": [
        "# Set random seeds\n",
        "torch.manual_seed(0)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(0)\n",
        "\n",
        "# Convert training and test data to TensorDatasets\n",
        "trainset = TensorDataset(torch.from_numpy(X_train_scaled).float(), \n",
        "                         torch.from_numpy(y_train).float())\n",
        "testset = TensorDataset(torch.from_numpy(X_test_scaled).float(), \n",
        "                        torch.from_numpy(y_test).float())\n",
        "\n",
        "# Create Dataloaders for our training and test data to allow us to iterate over minibatches \n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFXR1H3e72YR"
      },
      "source": [
        "### Step 2: Define our neural network architecture\n",
        "Next, we will define a model, feed-forward neural network for this chapter..\n",
        "For simplicity, we will use 3-layer, 2 hidden layers and 1 hidden-to-output layer, feed-forward net. Each layer is a fully-connected layer where the module `torch.nn.Linear` is the implementation of it. Also, we will apply ReLU activation for each layer.\n",
        "\n",
        "Basically, we are required to define a member method of `forward(self, x)` when we define a class for any customized network. It represents a forward pass of a computational graph and a backward pass (back-propagation) with automatic differentiation will be performed later based on this forward definition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RhB9Uem72YS"
      },
      "outputs": [],
      "source": [
        "class FeedForwardNet(nn.Module):\n",
        "    def __init__(self, n_input, n_hidden1, n_hidden2, n_output):\n",
        "        super().__init__()\n",
        "        self.hidden1 = nn.Linear(n_input, n_hidden1)\n",
        "        self.hidden2 = nn.Linear(n_hidden1, n_hidden2)\n",
        "        self.out = nn.Linear(n_hidden2, n_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.hidden1(x))\n",
        "        x = F.relu(self.hidden2(x))\n",
        "        x = torch.sigmoid(self.out(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9KjtMRI72YS"
      },
      "outputs": [],
      "source": [
        "# Instantiate our neural network\n",
        "net = FeedForwardNet(n_input=X_train_scaled.shape[1], n_hidden1=50, n_hidden2=20, n_output=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87Ru4ovF72YT"
      },
      "source": [
        "Alternatively, PyTorch gives us an easy way to define a model layer by layer using `nn.Sequential()` rather than creating a model class as we did above.  Here we define the same model as above much more simply:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOMO0OtS72YU"
      },
      "outputs": [],
      "source": [
        "# Build a feed-forward network\n",
        "n_input = X_train_scaled.shape[1]\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 20\n",
        "n_output = 1\n",
        "\n",
        "net = nn.Sequential(nn.Linear(n_input, n_hidden1),  # hidden layer 1\n",
        "                      nn.ReLU(), # hidden layer 1 activation\n",
        "                      nn.Linear(n_hidden1, n_hidden2), # hidden layer 2\n",
        "                      nn.ReLU(), # hidden layer 2 activation\n",
        "                      nn.Linear(n_hidden2, n_output), # output layer\n",
        "                      nn.Sigmoid()) # use sigmoid as output activation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k77JpNt372YU"
      },
      "source": [
        "### Step 3: Define a cost / loss function and optimizer\n",
        "We will use Binary Cross Entropy as our loss function, which is usually named `criterion` in PyTorch.  For our optimizer we will use stochastic gradient descent (SGD).\n",
        "\n",
        "When we create an optimizer in PyTorch, we need to pass in the parameters that we want to optimize (train), which are our weights. We can retrieve all trainable parameters of the model by calling `model.parameters()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyUAHvkM72YW"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define the cost / loss function\n",
        "cost_fn = nn.BCELoss()\n",
        "\n",
        "# Define the method of updating the weights each iteration (e.g. gradient descent)\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAwo2lAi72YX"
      },
      "source": [
        "### Step 4: Train the model\n",
        "To train our model, we perform the following four steps in a loop, using one input mini-batch at a time:  \n",
        "    1) Make a forward pass through the network to calculate the network output  \n",
        "    2) Use the network output to calculate the cost/loss  \n",
        "    3) Calculate the gradient of the cost/loss with respect to the weights by performing a backward pass through the network with loss.backward()  \n",
        "    4) Update the weights by taking a step with the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "i_vzsL1I72YY",
        "outputId": "48ae1407-1fa9-4bbd-f6c2-72046f4c8a04"
      },
      "outputs": [],
      "source": [
        "num_iter = 200\n",
        "cost = []\n",
        "\n",
        "net = net.to(device)\n",
        "net.train() # Set the model to training mode\n",
        "\n",
        "for epoch in range(num_iter):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for i, data in enumerate(trainloader):\n",
        "        \n",
        "        # Get the inputs X and labels y for the minibatch\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Zero the gradients of the weights each iteration\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Calculate the predictions and the cost/loss\n",
        "        outputs = net(inputs).view(-1) # Convert outputs to 1D array instead of 2D to match labels\n",
        "        loss = cost_fn(outputs, labels)\n",
        "        \n",
        "        # Use autograd to calculate the gradient of the cost with respect to each weight\n",
        "        loss.backward()\n",
        "        \n",
        "        # Use the optimizer to do the weights update\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store the cost/loss\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    cost.append(running_loss)\n",
        "        \n",
        "plt.plot(cost)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cost/loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwX2V2sx72YZ"
      },
      "source": [
        "### Step 5: Test the model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCZVHiJN72Ya",
        "outputId": "ec67d7f9-fbd5-43c6-d5a0-3bff7554b983"
      },
      "outputs": [],
      "source": [
        "# Set the model to evaluation mode\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "    # Set up lists to store true and predicted values\n",
        "    y_true = y_test.tolist\n",
        "    test_preds = []\n",
        "\n",
        "    # Calculate the predictions on the test set and add to list\n",
        "    for data in testloader:\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net.forward(inputs)\n",
        "        test_preds.extend(outputs.numpy().flatten().tolist())\n",
        "\n",
        "    # Convert the predictions to discrete and calculate the accuracy\n",
        "    test_preds = np.round(test_preds)\n",
        "    test_acc = np.sum(test_preds==y_test)/len(y_test)\n",
        "    print('Test set accuracy is {:.3f}'.format(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSzP_EyO72Yb"
      },
      "source": [
        "# Multiclass classification\n",
        "For a multi-class problem we use a softmax as the activation function to convert the outputs to probabilities, rather than sigmoid as we did in binary classification.  We also use cross-entropy (`nn.CrossEntropyLoss()`) as the loss function rather than negative log likelihood (`BCELoss()`) as we did previously.  Since PyTorch's `nn.CrossEntropyLoss()` applies a softmax before calculating the loss, we do not need to use a softmax on the output from the output layer, as we did with a sigmoid in our binary classification model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "jzQBE31q72Yb",
        "outputId": "7456e2be-6d9e-407a-b6b2-e52b0cf44134"
      },
      "outputs": [],
      "source": [
        "# Load the iris data\n",
        "iris = pd.read_csv('iris.csv')\n",
        "iris.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxWNUhn272Yc"
      },
      "outputs": [],
      "source": [
        "# Separate into X and y\n",
        "# Convert string species values in y to numerical codes for modeling\n",
        "X = iris.drop('species',axis=1)\n",
        "y = iris['species'].astype('category').cat.codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "100PQyXx72Yc",
        "outputId": "caaa1395-6d28-467f-8244-caf2207bb44a"
      },
      "outputs": [],
      "source": [
        "# Split data into training and test sets\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
        "print(\"Shape of X_train, y_train:\",X_train.shape,y_train.shape)\n",
        "print(\"Shape of X_test, y_test:\",X_test.shape,y_test.shape)\n",
        "\n",
        "# Let's scale our data to help the algorithm converge faster\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert y_train and y_test to arrays so all inputs are in NumPy\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BorXvW9k72Yd"
      },
      "outputs": [],
      "source": [
        "# Convert training and test data to TensorDatasets\n",
        "# When we do multiclass classification, PyTorch expects that labels are type LongTensor and inputs are FloatTensor\n",
        "trainset = TensorDataset(torch.from_numpy(X_train_scaled).float(), \n",
        "                         torch.from_numpy(y_train).long())\n",
        "testset = TensorDataset(torch.from_numpy(X_test_scaled).float(), \n",
        "                        torch.from_numpy(y_test).long())\n",
        "\n",
        "batchsize = 32\n",
        "# Create Dataloaders for our training and test data to allow us to iterate over minibatches \n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchsize, shuffle=False)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batchsize, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygi0fXY772Yd"
      },
      "outputs": [],
      "source": [
        "class Multiclass_Net(nn.Module):\n",
        "    def __init__(self, n_input, n_hidden1, n_hidden2, n_hidden3, n_output):\n",
        "        super().__init__()\n",
        "        self.hidden1 = nn.Linear(n_input, n_hidden1)\n",
        "        self.hidden2 = nn.Linear(n_hidden1, n_hidden2)\n",
        "        self.hidden3 = nn.Linear(n_hidden2, n_hidden3)\n",
        "        self.out = nn.Linear(n_hidden3, n_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.hidden1(x))\n",
        "        x = F.relu(self.hidden2(x))\n",
        "        x = F.relu(self.hidden3(x))\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "    \n",
        "# Instantiate our neural network\n",
        "# n_input=4 since we have 4 features\n",
        "# n_output=3 since we have 3 classes\n",
        "net = Multiclass_Net(n_input=4, n_hidden1=100, n_hidden2=50, n_hidden3=10, n_output=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfeeen4I72Ye"
      },
      "outputs": [],
      "source": [
        "def train_model(model,criterion,optimizer,trainloader,num_iter,device):\n",
        "    \n",
        "    model = model.to(device)\n",
        "    model.train() # Set the model to training mode\n",
        "    \n",
        "    cost = []\n",
        "    \n",
        "    for epoch in range(num_iter):\n",
        "\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i, data in enumerate(trainloader):\n",
        "\n",
        "            # Get the inputs X and labels y for the minibatch\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            # Zero the gradients of the weights each iteration\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Calculate the predictions and the cost/loss\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Use autograd to calculate the gradient of the cost with respect to each weight\n",
        "            loss.backward()\n",
        "\n",
        "            # Use the optimizer to do the weights update\n",
        "            optimizer.step()\n",
        "\n",
        "            # Add the loss to running loss for the epoch\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        cost.append(running_loss)\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "oJn_mmz072Ye",
        "outputId": "60fdf507-f3f6-4e51-a7e3-7549a8f3576d"
      },
      "outputs": [],
      "source": [
        "# Define the cost / loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Define the method of updating the weights each iteration\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "# Number of iterations (epochs) to train\n",
        "n_iter = 500\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Train model\n",
        "cost_path = train_model(net,criterion,optimizer,trainloader,n_iter,device)\n",
        "\n",
        "# Plot the cost over training\n",
        "plt.plot(cost_path)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnM2YjBA72Ye"
      },
      "outputs": [],
      "source": [
        "def test_model(model,test_loader,device):\n",
        "    # Turn autograd off\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Set the model to evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        # Set up lists to store true and predicted values\n",
        "        y_true = []\n",
        "        test_preds = []\n",
        "\n",
        "        # Calculate the predictions on the test set and add to list\n",
        "        for data in testloader:\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            # Feed inputs through model to get raw scores\n",
        "            logits = net.forward(inputs)\n",
        "            # Convert raw scores to probabilities (not necessary since we just care about discrete probs in this case)\n",
        "            probs = F.softmax(logits,dim=1)\n",
        "            # Get discrete predictions using argmax\n",
        "            preds = np.argmax(probs.numpy(),axis=1)\n",
        "            test_preds.extend(preds)\n",
        "            y_true.extend(labels)\n",
        "\n",
        "        # Calculate the accuracy\n",
        "        test_acc = np.sum(test_preds==y_test)/len(y_test)\n",
        "    \n",
        "    return test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_5lAMpM72Yf",
        "outputId": "a599a5fd-e01b-46c3-a3ad-7b3798df552f"
      },
      "outputs": [],
      "source": [
        "# Test model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "acc = test_model(net,testloader,device)\n",
        "print('Test set accuracy is {:.3f}'.format(acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UL1WMSJ72Yf"
      },
      "source": [
        "### Saving models\n",
        "To save PyTorch models for later use, we have two options:  \n",
        "1) We can save the `state_dict` which contains all the learned parameters of the model (the weights and biases) but not the architecture itself.  To use it, we instantiate a new model of the desired architecture and then load the saved `state_dict` to assign values to all the parameters in the model  \n",
        "2) We can alternatively save the entire model including the architecture, and then load it up and use it for prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Grq05psc72Yg"
      },
      "outputs": [],
      "source": [
        "# OPTION 1: Save the state dictionary of the model\n",
        "\n",
        "model_dir = 'saved_models/'\n",
        "os.makedirs(os.path.dirname(model_dir), exist_ok=True)\n",
        "filename = 'model_state_dict.pt'\n",
        "\n",
        "# Save the model's learned parameters (state_dict)\n",
        "torch.save(net.state_dict(), model_dir+filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTFKPmal72Yg",
        "outputId": "ea1957ce-ac26-4bad-a5f0-10784e5d7a08"
      },
      "outputs": [],
      "source": [
        "# Initialize new model and load state dict previously saved into it\n",
        "model = Multiclass_Net(n_input=4, n_hidden1=100, n_hidden2=50, n_hidden3=10, n_output=3)\n",
        "model.load_state_dict(torch.load(model_dir+filename))\n",
        "\n",
        "# Print model's state_dict\n",
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "    \n",
        "# Test loaded model\n",
        "acc = test_model(model,testloader,device)\n",
        "print()\n",
        "print('Test set accuracy is {:.3f}'.format(acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_55NHZE72Yh"
      },
      "outputs": [],
      "source": [
        "# OPTION 2: Save the entire model\n",
        "\n",
        "model_dir = 'saved_models/'\n",
        "os.makedirs(os.path.dirname(model_dir), exist_ok=True)\n",
        "filename = 'fullmodel.pt'\n",
        "\n",
        "# Save the entire model\n",
        "torch.save(net, model_dir+filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2dTOUdP72Yl",
        "outputId": "04e3fdb9-427c-4de6-d340-a86b7ecbe7db"
      },
      "outputs": [],
      "source": [
        "# Load model\n",
        "model2 = torch.load(model_dir+filename)\n",
        "\n",
        "# Test loaded model\n",
        "acc = test_model(model2,testloader,device)\n",
        "print('Test set accuracy is {:.3f}'.format(acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb8azyUC72Ym",
        "outputId": "191dac08-6291-4b1c-9b79-d6638dcd9f87"
      },
      "outputs": [],
      "source": [
        "# Run this cell only if working in Colab and you want to push new/changed files to GitHub\n",
        "# Note: you will need to manually save your current notebook to GitHub after running this cell\n",
        "\n",
        "# !git config --global user.email \"{git_email}\"\n",
        "# !git config --global user.name \"{git_user}\"\n",
        "# !git add --all #List files here that you have added or changed, other than this notebook\n",
        "# !git commit -m \"updated from colab\"\n",
        "# !git push"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDm_27IU8RR0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "pytorch_nn_intro.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
