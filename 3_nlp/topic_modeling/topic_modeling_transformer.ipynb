{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "923261bb",
   "metadata": {},
   "source": [
    "<a href='https://ai.meng.duke.edu'> = <img align=\"left\" style=\"padding-top:10px;\" src=https://storage.googleapis.com/aipi_datasets/Duke-AIPI-Logo.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling using BERT\n",
    "One of the downsides of using topic modeling methods which extract topics from documents converted to vectors using word counts/frequency is that there is no consideration given to semantic similarity of words/phrases.  For example, such an approach might not correctly recognize that a document which repeatedly includes the word \"covid-19\" shares the same topic as another document which uses the word \"coronavirus\".  \n",
    "\n",
    "An alternative approach is to use embedings to represent the text with vectors which capture the semantic meaning of the text.  One way to do this is to create a list of candidate topics, and then compare the embedding of each candidate topic to the embedding of each document (which is usually calculated as the mean of the embeddings of all words in the document).  We then presume that the candidate topics with embeddings closest to the embedding of the document (usually measured with cosine similarity) are the topics contained in the document. \n",
    "\n",
    "**Notes:** \n",
    "- This does not need to be run on GPU\n",
    "\n",
    "**References:**  \n",
    "- This demo notebook is inspired by [this article](https://towardsdatascience.com/keyword-extraction-with-bert-724efca412ea) from the creator of the [KeyBERT package](https://github.com/MaartenGr/KeyBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6c3cb6",
   "metadata": {},
   "source": [
    "## Get documents to tag with topics\n",
    "We will use BeautifulSoup to get the content of a few articles from the web and strip the text content from the hmtl.  The articles we will use for this example are news articles each relating to one or both of two primary themes: COVID-19 and Duke basketball.  Therefore we would expect the topics which we identify to be related to these two themes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e453c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get article\n",
    "article_urls = ['https://www.cbssports.com/college-basketball/news/duke-basketballs-game-vs-clemson-postponed-due-to-positive-covid-19-tests-in-blue-devils-program/',\n",
    "                'https://www.usatoday.com/story/news/health/2021/12/21/covid-holiday-safety-need-to-know/8968198002/',\n",
    "                'https://www.fayobserver.com/story/sports/college/basketball/2021/12/29/duke-blue-devils-basketball-recruiting-jon-scheyer-commits/9032663002/',\n",
    "                'https://www.today.com/health/health/covid-19-cold-flu-tell-difference-rcna10114',\n",
    "                'https://www.dukechronicle.com/article/2021/06/duke-mens-basketball-head-coach-jon-scheyer-mike-krzyzewski',\n",
    "                'https://www.hopkinsmedicine.org/health/conditions-and-diseases/coronavirus']\n",
    "article_text = []\n",
    "titles = []\n",
    "for url in article_urls:\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Extract body text from article\n",
    "    bodytext = soup.find_all('p')\n",
    "    bodytext = [i.text for i in bodytext]\n",
    "    bodytext = ' '.join(bodytext)\n",
    "    article_text.append(bodytext)\n",
    "    # Extract titles for articles\n",
    "    title = soup.find_all('h1')\n",
    "    title = title[0].text.strip()\n",
    "    titles.append(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b6842f",
   "metadata": {},
   "source": [
    "## Identify candidate topics\n",
    "We first need to create a set of candidate topics.  We will then embed each candidate topic and compare the embedding to the overall document embedding to see which candidate topics most closely match the overall article.  To create our list of candidate topics, we will extract all nouns and noun phrases (phrases including an adjective and a noun) from the articles, and these will be our candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aipi540/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Extract candidate 1-grams and 2-grams \n",
    "n_gram_range = (1, 2)\n",
    "vectorizer = CountVectorizer(ngram_range=n_gram_range, stop_words=stopwords.words('english'))\n",
    "vectorizer.fit(article_text)\n",
    "candidates = vectorizer.get_feature_names()\n",
    "\n",
    "# Get noun phrases and nouns from articles\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "all_nouns = set()\n",
    "for doc in article_text:\n",
    "    doc_processed = nlp(doc)\n",
    "    # Add noun chunks\n",
    "    all_nouns.add(chunk.text.strip().lower() for chunk in doc_processed.noun_chunks)\n",
    "    # Add nouns\n",
    "    for token in doc_processed:\n",
    "            if token.pos_ == \"NOUN\":\n",
    "                all_nouns.add(token.text)\n",
    "\n",
    "# Filter candidate topics to only those in the nouns set\n",
    "candidates = [c for c in candidates if c in all_nouns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed candidates and documents and find matching topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_topics(documents,candidates,num_topics):\n",
    "    model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "    # Encode each of the articles\n",
    "    doc_embeddings = [model.encode([doc]) for doc in documents]\n",
    "    # Encode the candidate topics\n",
    "    candidate_embeddings = model.encode(candidates)\n",
    "\n",
    "    # Calculate cosine similarity between each document and candidate topics\n",
    "    # Take the top candidate topics as keywords for each document\n",
    "    article_keywords = []\n",
    "    for doc in doc_embeddings:\n",
    "        scores = cosine_similarity(doc, candidate_embeddings)\n",
    "        keywords = [candidates[index] for index in scores.argsort()[0][-num_topics:]]\n",
    "        article_keywords.append(keywords)\n",
    "    \n",
    "    return article_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 0: Duke basketball games vs. Clemson, Notre Dame postponed due to positive COVID-19 tests in Blue Devils program\n",
      "Topic keywords: ['flu', 'viruses', 'coronavirus']\n",
      "\n",
      "Article 1: Vaccinated and test positive? What to know about omicron, COVID for this holiday season.\n",
      "Topic keywords: ['viruses', 'flu', 'coronavirus']\n",
      "\n",
      "Article 2: How did Duke basketball and Jon Scheyer keep up their major recruiting hot streak in December?\n",
      "Topic keywords: ['preseason', 'basketball', 'championship']\n",
      "\n",
      "Article 3: Is it COVID-19 or just a cold? Here's how to tell the difference\n",
      "Topic keywords: ['fever', 'coronavirus', 'flu']\n",
      "\n",
      "Article 4: Jon Scheyer to succeed Mike Krzyzewski after Duke men's basketball's 2021-22 season\n",
      "Topic keywords: ['doctor', 'coach', 'coaches']\n",
      "\n",
      "Article 5: What Is Coronavirus?\n",
      "Topic keywords: ['vaccines', 'vaccinations', 'coronavirus']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics = model_topics(article_text,candidates,num_topics=3)\n",
    "for i,keywords in enumerate(topics):\n",
    "    print('Article {}: {}'.format(i,titles[i]))\n",
    "    print('Topic keywords: {}'.format(keywords))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
